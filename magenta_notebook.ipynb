{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Python 3.7.6\n"
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改checkpoint变量名"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam_1\ntensor_name:  fully_connected/biases\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam\ntensor_name:  fully_connected/weights/Adam_1\ntensor_name:  fully_connected/weights/Adam\ntensor_name:  fully_connected/biases/Adam_1\ntensor_name:  fully_connected/weights\ntensor_name:  beta1_power\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam_1\ntensor_name:  beta2_power\ntensor_name:  fully_connected/biases/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias\ntensor_name:  global_step\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam_1\n"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "model_dir=\"/root/magenta/magenta/models/rl_tuner/checkpoint/src/model.ckpt-15321\" #checkpoint的文件位置\n",
    "# Read data from checkpoint file\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(model_dir)\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "# Print tensor name and values\n",
    "for key in var_to_shape_map:\n",
    "    print(\"tensor_name: \", key)  #输出变量名\n",
    "    #print(reader.get_tensor(key))   #输出变量值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /root/magenta/magenta/models/rl_tuner/rename_tf_variable.py:69: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\n2020-04-02 12:47:50.693803: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2020-04-02 12:47:50.700892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500015000 Hz\n2020-04-02 12:47:50.701129: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559038848510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-04-02 12:47:50.701154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\nWARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nRenaming beta1_power to beta1_power.\nRenaming beta2_power to beta2_power.\nRenaming fully_connected/biases to rnn_model/fully_connected/bias.\nRenaming fully_connected/biases/Adam to rnn_model/fully_connected/bias/Adam.\nRenaming fully_connected/biases/Adam_1 to rnn_model/fully_connected/bias/Adam_1.\nRenaming fully_connected/weights to rnn_model/fully_connected/weights.\nRenaming fully_connected/weights/Adam to rnn_model/fully_connected/weights/Adam.\nRenaming fully_connected/weights/Adam_1 to rnn_model/fully_connected/weights/Adam_1.\nRenaming global_step to global_step.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam.\nRenaming rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam_1 to rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias to rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias.\nRenaming rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam to rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam.\nRenaming rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1 to rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1.\nRenaming rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel to rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel.\nRenaming rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam to rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam.\nRenaming rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1 to rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1.\nModel directory: /root/magenta/magenta/models/rl_tuner/checkpoint/src\nMetagraph file: model.ckpt-15321.meta\nCheckpoint file: model.ckpt-15321\nWARNING:tensorflow:From /root/magenta/magenta/models/rl_tuner/rename_tf_variable.py:32: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n\nWARNING:tensorflow:From /root/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/training/queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nWARNING:tensorflow:From /root/magenta/magenta/models/rl_tuner/rename_tf_variable.py:33: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nWARNING:tensorflow:From /root/magenta/magenta/models/rl_tuner/rename_tf_variable.py:89: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n\n"
    }
   ],
   "source": [
    "!python /root/magenta/magenta/models/rl_tuner/rename_tf_variable.py \\\n",
    "--ckpt_path /root/magenta/magenta/models/rl_tuner/checkpoint/src \\\n",
    "--save_path /root/magenta/magenta/models/rl_tuner/checkpoint/model.ckpt-15321 \\\n",
    "--rename_var_src fully_connected/weights,fully_connected/biases \\\n",
    "--rename_var_dst rnn_model/fully_connected/weights,rnn_model/fully_connected/bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam_1\ntensor_name:  fully_connected/biases\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam\ntensor_name:  fully_connected/weights/Adam_1\ntensor_name:  fully_connected/weights/Adam\ntensor_name:  fully_connected/biases/Adam_1\ntensor_name:  fully_connected/weights\ntensor_name:  beta1_power\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam_1\ntensor_name:  beta2_power\ntensor_name:  fully_connected/biases/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias\ntensor_name:  global_step\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/bias/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/bias/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/kernel/Adam_1\ntensor_name:  rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/kernel\ntensor_name:  rnn/multi_rnn_cell/cell_0/attention_cell_wrapper/bias/Adam_1\n"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "model_dir=\"/root/magenta/magenta/models/rl_tuner/checkpoint/model.ckpt-15321\" #checkpoint的文件位置\n",
    "# Read data from checkpoint file\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(model_dir)\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "# Print tensor name and values\n",
    "for key in var_to_shape_map:\n",
    "    print(\"tensor_name: \", key)  #输出变量名\n",
    "    #print(reader.get_tensor(key))   #输出变量值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magenta.models.rl_tuner import rl_tuner\n",
    "from magenta.models.rl_tuner import rl_tuner_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设定输出文件存储路径\n",
    "SAVE_PATH = \"/root/magenta/magenta/models/rl_tuner/output/2020.4.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter settings\n",
    "ALGORITHM = 'q'\n",
    "REWARD_SCALER = 1\n",
    "OUTPUT_EVERY_NTH = 50000\n",
    "NUM_NOTES_IN_COMPOSITION = 64\n",
    "PRIME_WITH_MIDI = False\n",
    "NOTE_RNN_CHECKPOINT_DIR = '/root/magenta/magenta/models/rl_tuner/checkpoint'\n",
    "NOTE_RNN_TYPE = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_tuner_hparams = tf.contrib.training.HParams(random_action_probability=0.1,\n",
    "                                               store_every_nth=1,\n",
    "                                               train_every_nth=5,\n",
    "                                               minibatch_size=32,\n",
    "                                               discount_rate=0.5,\n",
    "                                               max_experience=100000,\n",
    "                                               target_network_update_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sys)\n",
    "importlib.reload(rl_tuner_ops)\n",
    "importlib.reload(rl_tuner)\n",
    "rl_tuner.reload_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_net = rl_tuner.RLTuner(SAVE_PATH, \n",
    "                          dqn_hparams=rl_tuner_hparams, \n",
    "                          algorithm=ALGORITHM,\n",
    "                          reward_scaler=REWARD_SCALER,\n",
    "                          output_every_nth=OUTPUT_EVERY_NTH,\n",
    "                          num_notes_in_melody=NUM_NOTES_IN_COMPOSITION,\n",
    "                          note_rnn_checkpoint_dir=NOTE_RNN_CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate initial music sequence before training with RL\n",
    "rl_net.generate_music_sequence(visualize_probs=True, title='pre_rl', length=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_net.train(num_steps=1000000, exploration_period=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rewards received during training. Improves as chance of random exploration action decreases.\n",
    "rl_net.plot_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rewards received during calls to evaluation function throughout training. \n",
    "# Does not include exploration or random actions.\n",
    "rl_net.plot_evaluation()"
   ]
  }
 ]
}